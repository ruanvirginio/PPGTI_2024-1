{"cells":[{"cell_type":"markdown","metadata":{"id":"3i0ZTykS3uka"},"source":["FILTRAR CNPJS INATIVOS\n","ADICIONAR DSC LOGRADOURO NA CONSULTA\n"]},{"cell_type":"code","execution_count":38,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["File downloaded successfully and saved to C:\\Users\\ruanv\\OneDrive\\Documentos\\Mestrado\\Projeto BD_EngSoft\\PPGTI_2024-1\\Farmacias_Credenciadas.xlsx\n"]}],"source":["import requests\n","\n","url = \"https://www.gov.br/saude/pt-br/composicao/sectics/farmacia-popular/arquivos/farmacias_credenciadas_pfpb_atualizada.xlsx/@@download/file\"\n","file_path = r'C:\\Users\\ruanv\\OneDrive\\Documentos\\Mestrado\\Projeto BD_EngSoft\\PPGTI_2024-1\\Farmacias_Credenciadas.xlsx'\n","\n","response = requests.get(url)\n","if response.status_code == 200:\n","    with open(file_path, 'wb') as file:\n","        file.write(response.content)\n","    print(f\"File downloaded successfully and saved to {file_path}\")\n","else:\n","    print(f\"Failed to download the file. Status code: {response.status_code}\")\n"]},{"cell_type":"code","execution_count":39,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["File downloaded successfully and saved to C:\\Users\\ruanv\\OneDrive\\Documentos\\Mestrado\\Projeto BD_EngSoft\\PPGTI_2024-1\\Medicamentos_Credenciadas.pdf\n"]}],"source":["import requests\n","\n","url = \"https://www.gov.br/saude/pt-br/composicao/sectics/farmacia-popular/arquivos/elenco-de-medicamentos-e-insumos-pfpb-02-2024\"\n","file_path = r'C:\\Users\\ruanv\\OneDrive\\Documentos\\Mestrado\\Projeto BD_EngSoft\\PPGTI_2024-1\\Medicamentos_Credenciadas.pdf'\n","\n","response = requests.get(url)\n","if response.status_code == 200:\n","    with open(file_path, 'wb') as file:\n","        file.write(response.content)\n","    print(f\"File downloaded successfully and saved to {file_path}\")\n","else:\n","    print(f\"Failed to download the file. Status code: {response.status_code}\")\n","\n","\n","\n"]},{"cell_type":"code","execution_count":44,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["                                         Medicamentos\n","0                        Brometo de ipratrópio 0,25mg\n","1                Dipropionato de beclometasona 200mcg\n","2                Dipropionato de beclometasona 250mcg\n","3                 Dipropionato de beclometasona 50mcg\n","4                        Sulfato de salbutamol 100mcg\n","5                           Sulfato de salbutamol 5mg\n","6                      Cloridrato de metformina 500mg\n","7    Cloridrato de metformina 500mg - ação prolongada\n","8                      Cloridrato de metformina 850mg\n","9                                   Glibenclamida 5mg\n","10                   Insulina humana regular 100ui/ml\n","11                           Insulina humana 100ui/ml\n","12                                      Atenolol 25mg\n","13                        Besilato de anlodipino 5 mg\n","14                                     Captopril 25mg\n","15                     Cloridrato de propranolol 40mg\n","16                             Hidroclorotiazida 25mg\n","17                           Losartana potássica 50mg\n","18                          Maleato de enalapril 10mg\n","19                              Espironolactona 25 mg\n","20                                   Furosemida 40 mg\n","21                      Succinato de metoprolol 25 mg\n","22               Acetato de medroxiprogesterona 150mg\n","23     Etinilestradiol 0,03mg + levonorgestrel 0,15mg\n","24                               Noretisterona 0,35mg\n","25  Valerato de estradiol 5mg + enantato de noreti...\n","26                          Alendronato de sódio 70mg\n","27                               Absorvente higiênico\n","28                                  Sinvastatina 10mg\n","29                                  Sinvastatina 20mg\n","30                                  Sinvastatina 40mg\n","31                    Carbidopa 25mg + levodopa 250mg\n","32    Cloridrato de benserazida 25mg + levodopa 100mg\n","33                           Maleato de timolol 2,5mg\n","34                             Maleato de timolol 5mg\n","35                                  Fralda geriátrica\n","36                                   Budesonida 32mcg\n","37                                   Budesonida 50mcg\n","38           Dipropionato de beclometasona 50mcg/dose\n","39                               Dapagliflozina 10 mg\n","40                                                   \n"]}],"source":["import fitz  # PyMuPDF\n","import pandas as pd\n","import re\n","\n","# Função para extrair texto de todas as páginas do PDF\n","def extract_text_from_pdf(pdf_path):\n","    doc = fitz.open(pdf_path)\n","    text = \"\"\n","    for page in doc:\n","        text += page.get_text()\n","    return text\n","\n","# Função para filtrar linhas que contêm letras minúsculas\n","def filter_text(text):\n","    # Dividir o texto em linhas\n","    lines = text.split('\\n')\n","    \n","    # Filtrar linhas que contêm letras minúsculas\n","    filtered_lines = [line for line in lines if not re.search('[A-Z]', line)]\n","    \n","    return filtered_lines\n","\n","# Função para processar o texto extraído em um dataframe\n","def process_text_to_dataframe(lines):\n","    if not lines:\n","        return pd.DataFrame()\n","\n","    # Supondo que a primeira linha contém os cabeçalhos das colunas\n","    headers = re.split(r'\\s{2,}', lines[0].strip())\n","    \n","    # Processar linhas subsequentes\n","    data = []\n","    for line in lines[1:]:\n","        # Dividir a linha em colunas com base em espaços múltiplos\n","        columns = re.split(r'\\s{2,}', line.strip())\n","        if len(columns) == len(headers):  # Certificar-se de que o número de colunas é consistente\n","            data.append(columns)\n","    \n","    # Criar o DataFrame\n","    df = pd.DataFrame(data, columns=headers)\n","    \n","    # Remover linhas vazias\n","    df.dropna(how='all', inplace=True)\n","    \n","    # Remover duplicatas\n","    df.drop_duplicates(inplace=True)\n","    \n","    return df\n","\n","# Caminho para o arquivo PDF\n","pdf_path = 'Medicamentos_Credenciadas.pdf'\n","\n","# Extrair texto do PDF\n","pdf_text = extract_text_from_pdf(pdf_path)\n","\n","# Filtrar o texto para remover linhas com letras minúsculas\n","filtered_text = filter_text(pdf_text)\n","\n","# Processar o texto filtrado para criar o DataFrame\n","df = process_text_to_dataframe(filtered_text)\n","\n","# Adicionar um cabeçalho personalizado\n","df.columns = ['Medicamentos']\n","\n","# Capitalizar a primeira letra de cada linha\n","df['Medicamentos'] = df['Medicamentos'].str.capitalize()\n","\n","# Exibir o DataFrame\n","print(df)\n","\n","# Salvar o DataFrame em um arquivo CSV\n","df.to_csv('Medicamentos.csv', index=False)\n"]},{"cell_type":"code","execution_count":41,"metadata":{"id":"kA-NsWUc3uke"},"outputs":[{"ename":"ValueError","evalue":"Excel file format cannot be determined, you must specify an engine manually.","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[1;32mIn[41], line 36\u001b[0m\n\u001b[0;32m     33\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;66;03m# Ler o arquivo .xlsx e coletar os dados da coluna CNPJ\u001b[39;00m\n\u001b[1;32m---> 36\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_excel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskiprows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m12\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43musecols\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mB:H\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;66;03m# df = df[(df['UF'] == \"AC\")] # Possível filtro de estafos do banco\u001b[39;00m\n\u001b[0;32m     39\u001b[0m cnpjs \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCNPJ\u001b[39m\u001b[38;5;124m'\u001b[39m]\n","File \u001b[1;32mc:\\Users\\ruanv\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\excel\\_base.py:504\u001b[0m, in \u001b[0;36mread_excel\u001b[1;34m(io, sheet_name, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, date_format, thousands, decimal, comment, skipfooter, storage_options, dtype_backend, engine_kwargs)\u001b[0m\n\u001b[0;32m    502\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(io, ExcelFile):\n\u001b[0;32m    503\u001b[0m     should_close \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 504\u001b[0m     io \u001b[38;5;241m=\u001b[39m \u001b[43mExcelFile\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    505\u001b[0m \u001b[43m        \u001b[49m\u001b[43mio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    506\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    507\u001b[0m \u001b[43m        \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    508\u001b[0m \u001b[43m        \u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    509\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    510\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m engine \u001b[38;5;129;01mand\u001b[39;00m engine \u001b[38;5;241m!=\u001b[39m io\u001b[38;5;241m.\u001b[39mengine:\n\u001b[0;32m    511\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    512\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEngine should not be specified when passing \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    513\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124man ExcelFile - ExcelFile already has the engine set\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    514\u001b[0m     )\n","File \u001b[1;32mc:\\Users\\ruanv\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\excel\\_base.py:1567\u001b[0m, in \u001b[0;36mExcelFile.__init__\u001b[1;34m(self, path_or_buffer, engine, storage_options, engine_kwargs)\u001b[0m\n\u001b[0;32m   1563\u001b[0m     ext \u001b[38;5;241m=\u001b[39m inspect_excel_format(\n\u001b[0;32m   1564\u001b[0m         content_or_path\u001b[38;5;241m=\u001b[39mpath_or_buffer, storage_options\u001b[38;5;241m=\u001b[39mstorage_options\n\u001b[0;32m   1565\u001b[0m     )\n\u001b[0;32m   1566\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ext \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1567\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1568\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExcel file format cannot be determined, you must specify \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1569\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124man engine manually.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1570\u001b[0m         )\n\u001b[0;32m   1572\u001b[0m engine \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mget_option(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mio.excel.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mext\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.reader\u001b[39m\u001b[38;5;124m\"\u001b[39m, silent\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m   1573\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m engine \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n","\u001b[1;31mValueError\u001b[0m: Excel file format cannot be determined, you must specify an engine manually."]}],"source":["import pandas as pd\n","import requests\n","from geopy.geocoders import ArcGIS\n","import time\n","\n","geolocator = ArcGIS()\n","\n","def consultar_cnpj_brasilio(cnpj):\n","    url = f\"https://brasilapi.com.br/api/cnpj/v1/{cnpj}\"\n","    response = requests.get(url)\n","    if response.status_code == 200:\n","        data = response.json()\n","        info = {\n","            \"CNPJ\": data.get(\"cnpj\", \"\"),\n","            \"Nome\": data.get(\"razao_social\", \"\"),\n","            \"Fantasia\": data.get(\"nome_fantasia\", \"\"),\n","            \"Tipo_Logradouro\": data.get(\"descricao_tipo_de_logradouro\", \"\"),\n","            \"Logradouro\": data.get(\"logradouro\", \"\"),\n","            \"Número\": data.get(\"numero\", \"\"),\n","            \"Município\": data.get(\"municipio\", \"\"),\n","            \"Bairro\": data.get(\"bairro\", \"\"),\n","            \"UF\": data.get(\"uf\", \"\"),\n","            \"Telefone\": data.get(\"telefone\", \"\"),\n","            \"Situação\": data.get(\"descricao_situacao_cadastral\", \"\")\n","        }\n","        return info\n","    return None\n","\n","def get_coordinates(tipo_logradouro, logradouro, numero, bairro, cidade, estado):\n","    location = geolocator.geocode(f\"{tipo_logradouro} +   + {logradouro}, {numero}, {bairro} ,{cidade}, {estado}\")\n","    if location:\n","        return location.latitude, location.longitude\n","    return None\n","\n","# Ler o arquivo .xlsx e coletar os dados da coluna CNPJ\n","df = pd.read_excel(file_path, skiprows=12, usecols=\"B:H\")\n","# df = df[(df['UF'] == \"AC\")] # Possível filtro de estafos do banco\n","\n","cnpjs = df['CNPJ']\n","\n","# Tratar os CNPJs removendo \".\", \"/\" e \"-\"\n","cnpjs = cnpjs.str.replace(\".\", \"\").str.replace(\"/\", \"\").str.replace(\"-\", \"\")\n","\n","# Processar cada CNPJ e obter informações da Brasil.io com timer\n","final_data = []\n","for cnpj in cnpjs:\n","    cnpj_info = consultar_cnpj_brasilio(cnpj)\n","    if cnpj_info:\n","        tipo_logradouro = cnpj_info.get(\"Tipo_Logradouro\", \"\")\n","        logradouro = cnpj_info.get(\"Logradouro\", \"\")\n","        numero = cnpj_info.get(\"Número\", \"\")\n","        bairro = cnpj_info.get(\"Bairro\", \"\")\n","        cidade = cnpj_info.get(\"Município\", \"\")\n","        estado = cnpj_info.get(\"UF\", \"\")\n","        situacao = cnpj_info.get(\"descricao_situacao_cadastral\", \"\")\n","\n","        coordinates = get_coordinates(tipo_logradouro, logradouro, numero, bairro, cidade, estado)\n","        if coordinates:\n","            cnpj_info[\"Latitude\"] = coordinates[0]\n","            cnpj_info[\"Longitude\"] = coordinates[1]\n","            final_data.append(cnpj_info)\n","        else:\n","            print(\"Coordenadas não encontradas para o endereço fornecido.\")\n","    else:\n","        print(f\"Não foi possível obter informações para o CNPJ {cnpj}\")\n","    time.sleep(0.06)  # Esperar um tempo entre consultas\n","\n","# Criar DataFrame final e salva    r em um arquivo .csv\n","final_df = pd.DataFrame(final_data)\n","final_df.to_csv('dados_finais.csv', index=False)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import os\n","import pandas as pd\n","\n","# Diretório contendo os arquivos CSV\n","diretorio = r'C:\\Users\\ruanv\\OneDrive\\Documentos\\Mestrado\\Projeto BD_EngSoft\\PPGTI_2024-1\\dados_estado'\n","\n","# Lista para armazenar os DataFrames de cada arquivo CSV\n","frames = []\n","\n","# Percorrer todos os arquivos na pasta\n","for arquivo in os.listdir(diretorio):\n","    if arquivo.endswith('.csv'):\n","        caminho_arquivo = os.path.join(diretorio, arquivo)\n","        # Lê o arquivo CSV e adiciona ao DataFrame\n","        df = pd.read_csv(caminho_arquivo, dtype=str)\n","        frames.append(df)\n","\n","# Concatena todos os DataFrames em um único DataFrame\n","df_final = pd.concat(frames, ignore_index=True)\n","\n","# Exibe o DataFrame resultante\n","print(df_final)\n","\n","# Se desejar, você pode salvar o DataFrame unificado em um novo arquivo CSV\n","df_final.to_csv('resultado.csv', index=False)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import csv\n","import json\n","\n","def csv_to_json(csv_file):\n","    json_data = []\n","\n","    with open(csv_file, 'r', encoding='utf-8') as file:\n","        csv_reader = csv.DictReader(file)\n","        for row in csv_reader:\n","            if row['Situação'] == 'ATIVA':\n","                json_row = {\n","                    \"nome\": row['Nome'],\n","                    \"longLat\": [float(row['Longitude']), float(row['Latitude'])],\n","                    \"nomeFantasia\": row['Fantasia'],\n","                    \"endereco\": {\n","                        \"rua\": row['Tipo_Logradouro'] + ' ' + row['Logradouro'],\n","                        \"numero\": row['Número'],\n","                        \"bairro\": row['Bairro'],\n","                        \"municipio\": row['Município'],\n","                        \"estado\": row['UF']\n","                    }\n","                }\n","                json_data.append(json_row)\n","\n","    return json_data\n","\n","def main():\n","    csv_file = \"resultado.csv\"  \n","    json_data = csv_to_json(csv_file)\n","    with open(\"dados.json\", 'w', encoding='utf-8') as json_file:\n","        json.dump(json_data, json_file, ensure_ascii=False, indent=2)\n","\n","if __name__ == \"__main__\":\n","    main()\n"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"}},"nbformat":4,"nbformat_minor":0}
